{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTrGz4E-k-kH",
        "outputId": "4d9bc70e-116e-49fa-fe38-3109307cd2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Collecting openai\n",
            "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 2.12.0\n",
            "    Uninstalling openai-2.12.0:\n",
            "      Successfully uninstalled openai-2.12.0\n",
            "Successfully installed openai-2.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-HcLXXEDN0R",
        "outputId": "d3a3f045-9c88-4297-c52b-75c305145702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Maya didn’t set out to become a Generative AI Engineer. She set out to stop wasting time.\\n\\nAt her first job after university, she worked on a product analytics team at a mid-sized e-commerce company. Every week,']\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "def comp(prompt, max_tokens=50):\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        input=prompt,\n",
        "        max_output_tokens=max_tokens,\n",
        "    )\n",
        "    #print(response.output)\n",
        "    results = []\n",
        "\n",
        "    # response.output is a list of ResponseOutputMessage objects\n",
        "    for item in response.output:\n",
        "        if item.type == \"message\":\n",
        "            for content in item.content:\n",
        "                if content.type == \"output_text\":\n",
        "                    results.append(content.text.strip())\n",
        "\n",
        "    return results\n",
        "PROMPT = \"Write a success story of a Generative AI Engineer.\"\n",
        "print(comp(PROMPT, max_tokens=50))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAgAlPfYs6EY",
        "outputId": "d8f69d3d-7487-4e11-9af6-74dd279a7e63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Client (Kevin Hart style):** Yo, I bought this “premium” wine bottle and it tastes like somebody rinsed grapes in a sock.  \\n**Businessman (Shakespeare style):** Good sir, thou dost mistake nectar for ambrosia; thy tongue is but untrained.\\n\\n**Client:** Untrained? My tongue got a black belt in flavor, okay—this joint is disrespectful.  \\n**Businessman:** Nay, the bottle is noble; ‘tis thy expectations that be peevish and loud.\\n\\n**Client:** Loud? I’m loud ‘cause my wallet got quiet after you charged me “exclusive” money.  \\n**Businessman:** The coin thou gav’st was fair tribute for rarity; complain not of fortune’s artistry.\\n\\n**Client:** Rarity? Yeah, rare like “rarely drinkable”—I took one sip and saw my ancestors.  \\n**Businessman:** Perchance thou sipp’st too boldly; the wine revealeth truths to fragile hearts.\\n\\n**Client:** Fragile? Sir, my heart fine—my stomach is filing a lawsuit.  \\n**Businessman:** Thy belly is a fickle judge; the fault lies not in our craft, but in thy constitution.\\n\\n**Client:** So the bottle ain’t wrong, the label ain’t wrong, the price ain’t wrong—only me, huh?  \\n**Businessman:** Aye, for the stars align in our favor; thou alone stand’st crosswise to reason.\\n\\n**Client:** Cool, cool… so I paid $80 to get roasted in Old English. I want a refund.  \\n**Businessman:** Refund? Alas, good sir, we deal in wine, not repentance; return is but a dream.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "PROMPT = \"\"\"Write a short conversation between client and businessman about a wine bottle purchase.\n",
        "Client is not happy with the purchase and the businessman is not accepting his mistake.\n",
        "Make the conversation sarcastic.\n",
        "Each Response should have atmost 2 lines.\n",
        "The client should talk like Kevin Hart and businessman should  talk like Shakespeare.\n",
        "\"\"\"\n",
        "comp(PROMPT, max_tokens=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj2BpjmttQEQ",
        "outputId": "96538a37-593c-4a5a-ab32-81c83bac1960"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Client: I want a water bottle.  \\nWorker: I don't have any water botlles.  \\nClient: But I want water bottles.  \\nWorker: I don’t sell them anymore… because people kept forgetting them and buying new ones.  \\nClient: So what am I supposed to do?  \\nWorker: Follow me for a second.  \\nClient: Where are we going?  \\nWorker: To the back. I started a little “Lost & Found Bottle Library.” Cleaned, sanitized, and sorted.  \\nClient: A bottle library?  \\nWorker: Yep. If you forgot yours, you can borrow one for free. If you have extras at home, you can donate.  \\nClient: That’s… actually really nice. But I didn’t forget one—I just don’t have one.  \\nWorker: Then you can keep one. No charge.  \\nClient: Seriously? Why?  \\nWorker: Because this whole thing started when a kid came in thirsty and didn’t have money. I gave him my own bottle. People saw it, and they began leaving theirs behind on purpose.  \\nClient: Wait… I think I was that kid. Years ago. You had a sticker of a little whale on your bottle.  \\nWorker: You remember that? I kept the sticker. It’s right here.  \\nClient: I can’t believe it… you’re the reason I started carrying a bottle everywhere.  \\nWorker: Then take this one—same brand, same whale.  \\nClient: I came in to buy a bottle… and walked into a second chance.  \\nWorker: Just promise me one thing.  \\nClient: What?  \\nWorker: When you’re able, bring back one extra bottle for someone else.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "PROMPT = \"\"\"Complete the below conversation between a client and a worker.\n",
        "Make the conversation have a wholesome plot twist.\n",
        "Conversation : ###\n",
        "Client: I want a water bottle.\n",
        "Worker: I don't have any water botlles.\n",
        "Client: But I want water bottles.\n",
        "Worker:\n",
        "###\n",
        "\"\"\"\n",
        "comp(PROMPT, max_tokens=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-exGo45tat4",
        "outputId": "70f91fc1-208d-475b-93f1-26211881f5de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['वह एक अच्छा व्यवसायी है।']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "PROMPT = \"\"\"\n",
        "Translate the below text in Hindi.\n",
        "Text:###\n",
        "He is a good Business man.\n",
        "###\n",
        "\"\"\"\n",
        "comp(PROMPT, max_tokens=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgj79TEqt-0-",
        "outputId": "b0195cd1-9f44-4ae6-ade7-e03c9d020c08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Summary:**  \\nA hare challenges a tortoise to a race to prove his superiority. The hare sprints ahead but, overconfident, stops to nap. The tortoise steadily continues and reaches the finish line first, winning humbly.\\n\\n**Key points:**\\n- The hare is fast but arrogant; the tortoise is slow but steady and determined.  \\n- The hare initiates the race to show off.  \\n- The hare gains an early lead and then naps due to overconfidence.  \\n- The tortoise keeps moving consistently and wins the race.  \\n- Core lesson: perseverance and humility can beat talent without discipline.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "PROMPT = \"\"\"\n",
        "Summarize the below text and extract the key points.\n",
        "Text:###\n",
        "This is an extremely popular story about a hare and a tortoise.\n",
        "The hare is an animal that is known to move quickly, while a tortoise is one to move slowly.\n",
        "One day, the hare challenged the tortoise to a race simply to prove that he was the best. The tortoise agreed.\n",
        "Once the race began the hare was easily able to get a head start. Upon realizing that the tortoise is far behind. The overconfident hare decided to take a nap.\n",
        "Meanwhile the tortoise, who was extremely determined and dedicated to the race was slowly nearing the finish line.\n",
        "The tortoise won the race while the hare napped. Most importantly he did it with humility and without arrogance.\n",
        "###\n",
        "\"\"\"\n",
        "comp(PROMPT, max_tokens=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi5bd6fZtSTR",
        "outputId": "c8da9d96-f51c-48ff-9274-8d7550b5719c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start chatting with the bot (type 'quit' to stop)!\n",
            "User: Ok Bye\n",
            "Bot: Bye. If you need anything later, just come back.\n",
            "User: Hi\n",
            "Bot: Hi—what can I help you with today?\n",
            "User: Nothing thanks\n",
            "Bot: Understood. If you need anything later, just tell me what you’re trying to do and I’ll help.\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "def chatbot():\n",
        "    system_prompt = \"You are a helpful assistant.\"\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        if user_input.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        response = client.responses.create(\n",
        "            model=\"gpt-5.2\",\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Simplest & safest way to get text output\n",
        "        print(f\"Bot: {response.output_text}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
        "    chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv3xYa_RlCMm",
        "outputId": "47f908a5-4f86-4ffa-a31d-e02fef95065e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start chatting with the bot (type 'quit' to stop)!\n",
            "User: Hi\n",
            "Bot: Hi—how can I help today?\n",
            "User: Who is Narendra Modi\n",
            "Bot: Narendra Modi (Narendra Damodardas Modi, born 1950) is an Indian politician who has served as the Prime Minister of India since 2014. He is a leader of the Bharatiya Janata Party (BJP) and was previously the Chief Minister of the state of Gujarat from 2001 to 2014.\n",
            "User: What is his D.O.B\n",
            "Bot: Narendra Modi’s date of birth is **17 September 1950**.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "def chatbot():\n",
        "    # Store conversation history\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        if user_input.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        # Add user message to memory\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.responses.create(\n",
        "            model=\"gpt-5.2\",\n",
        "            input=messages\n",
        "        )\n",
        "\n",
        "        # Extract assistant reply\n",
        "        bot_reply = response.output_text\n",
        "        print(f\"Bot: {bot_reply}\")\n",
        "\n",
        "        # Add assistant reply back to memory\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Start chatting with the bot (type 'quit' to stop)!\")\n",
        "    chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_04WTli9o2I3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nyIp7yZqZyU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}